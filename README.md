# 初めに
お読みいただきありがとうございます。試運転したい場合は、製作者までお願いします。
# 基本情報
## 使用したもの
+ 開発環境    
    + [Google colab](https://colab.research.google.com/)
    + [Visual Studio code](https://code.visualstudio.com/) 
+ プログラミング言語
    + [Python 3.12](https://www.python.org/downloads/release/python-3120/)   
+ べースモデル
    + [elyza/Llama-3-ELYZA-JP-8B](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B)
+ その他    
    + TokenizerやTrainer等のPython PIPツール。
## 説明
+ colabについて
    + Google Colab（Google Colaboratory） は、ブラウザ上で Python を記述・実行できるクラウドベースのサービスです。特にデータサイエンスや機械学習の分野で広く利用されており、高い安定性と信頼性を誇ります。環境構築不要で、Python等のコードをすぐに実行可能です。Googleのクラウドサーバー上で動作するため、ローカル環境の性能に依存せず、GPUやTPU などの高性能ハードウェアを無料で利用できます。
+ Pythonについて
    + AI学習に限らず、自動化ソフトや計算ソフトなど様々な分野で使われている言語です。pipコマンドを使うことで、追加モジュールをインストールし機能を拡張できます。比較的難易度が低いですが、世界中で最も使われている言語のひとつです。
+ ベースモデルについて
    + AIを作るためには、まず言葉を教える必要があります。人間と同じで読み書きを教えなければいけません。その後は、単語に関する知識や文法を教える必要があり、莫大な期間と労力を費やします。そこで、日本語が喋れる段階まで成長したAIを用意します。これがベースモデルです。ここでこのAIの主機能となるデータを追加で学習させ、ユーザーの指示に対して答えられるように訓練します。
+ elyza/Llama-3-ELYZA-JP-8Bについて
    + Llama-3-ELYZA-JP-8Bは、日本語に特化した大規模言語モデルで、ELYZA社が開発したものであり、Meta社のLlama 3というモデルのシリーズを基にしています。すさまじい量の言語情報が訓練されており、文章の生成能力は、GPT-3.5に匹敵します。詳しくは、[モデルが提供されているページ](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B)をご覧ください。
+ 学習について
    + 今回は、枕草子の全文をQA形式でトレーニングさせました。短歌等は学習するうえでAIが混乱するため除外しました。JSONLファイルを使用しております。詳しくは、添付したGitHubのリンクを開いていただき、その中の「makura_no_soshi_qa.jsonl」というファイルをご覧ください。学習では、清少納言が枕草子に記したことから、感性や文体の特徴（読点の頻度など）をAIで再現できるようにしております。
+ 回答の生成について
    + 回答生成時は、質問を単語に分け、枕草子内に出てくる文章の中で一致もしくは類似するものを見つけます。この時に、現代語での質問も、ネット上のデータベースを参考に、単語ごとに歴史的仮名遣いや昔の言い方に変換されます。複数がマッチした場合は、すべての原文をもとに、自然な文に変換します。この際、絶対に現代語が出力されないようにしています。万が一、学習データに一致する情報がなかった際は、インターネット上のデータを参照するようにしております。ただし、この際に生成される回答は、枕草子の文体を使用しているだけであり、内容が清少納言の感性に一致するとは言えません。今後は、この点を修正しようと思っております。

# 用語解説
### GPU
+ グラフィック演算装置のこと。本来は映像処理をする装置だが、AI学習をするうえで重要な並列演算が得意なため、AI開発では最も重要な部品である。高いもので1000万を超える。
### JSON
+ JavaScript Object Notationのこと。データをコンピューターが認識できるように入力する書き方のルール。もともとJavaScriptというプログラミング言語の書き方をもとに設計された。今では、軽量にデータを構造化できるうえ、とてもシンプルであるため、あらゆるところで使われている。
### JSONL
+ JSONの亜種。JSONとは違い、データは一つのブロックを１行ごとに入力する。AIなどの処理において、１行データのほうが良いため、よく使われる。
### ライブラリ
+ Pythonで使用できる追加機能のようなもの。公式だけでなく、有志によって製作されているものもある。pipというコマンドでインストールする
### Hugging Face
+ AIにおけるGitHub。AIベースモデルや、学習データなどが、全員が閲覧・ダウンロード・使用できる状態で公開されている。2024年中期に使用できるモデルの数が100万を突破した。PythonでAI学習を支援できるように、ライブラリも公開している。
### 量子化
+ AI学習に使用するデータを高精度、例えば32bitから低精度、例えば8bitに変換すること。学習に必要なPCスペックが下げられたり、学習時間の短縮などのメリットがあるが、精度を低下させるため、データの質が悪化するリスクがある。ちょうどいいレベルまで量子化させることが大事。
### LoRA
+ Low-Rank Adaptationのこと。2022年に提案された。今まではAIを作るために、ベースモデルから作る必要があったが、ベースモデルをあらかじめ用意し、用途ごとに学習データを学習させ、学習データを切り替えるだけで、他の用途にも使えるようになった。この技術のおかげで、生成ＡＩが急速に増えた。さらに軽量なものに、QLoRAというものもある。
### トークン
+ 学習データのサイズを表す。日本語なら2文字で１トークン程。EOSトークンやPADトークンは別の意味。
### EOSトークン
+ CLM（後述）や LLM（後述）において、文章を終わりを指示する文字列のこと。elyza/Llama-3-ELYZA-JP-8Bでは、<|eot_id|>がEOSトークンとなっている。これが誤送信されると、生成が止まってしまう
### PADトークン
+ テキストのデータをそろえるために使う特殊トークン。正しく使うことで、AIの生成を支援できる
### CLM
+ 小規模言語モデルのこと。言語データが特定の対象に特化している。
### LLM
+ 大規模言語モデルのこと。様々な分野において、自然な文章構成を得意とする。データ量が非常に多い。最近、楽天が国内最大級モデルを開発してニュースになった。今回使用のelyza/Llama-3-ELYZA-JP-8BはLLMである。
### トークナイザー
+ 学習データを先述の「トークン」に分割するツールのこと。すべてのトークンにIDが割り当てられ、学習・生成のもととなる。
### 推論
+ 簡単に言えば答えを生成すること。学習データやインターネット上のデータを参照して答えを生成すること。推論時にもAIはデータなどを分析、自己改善学習する。
### Trainer
+ 名前の通り、AIに学習させるツール。プログラム内で、学習の手順や設定を調整する。
### エポック（epoch）
+ AIに同じデータを反復学習させること。エポック数はその回数。エポック数が少なくても多すぎてもよくない。たとえば、計算ドリルがあったとして、最後までやったとする。これがエポック数１である。しかし、何も知らない状態で１回やっただけでは定着しない。これは、学習不足である。そこで、５周繰り返した。これがエポック数５である。計算の手順や公式を理解し、数字が違っても似たような問題が解けるようになるだろう。もっと解けるようになりたいと思い、１００周やった。エポック数１００である。すると、答えと問題を憶えてしまい、９０回近くは同じものを書き続けるということをしたことになる。こうすると時間の無駄であるし、定着せず、数字が違ったりしたら答えを覚えているわけがないため、解けない。これが過学習である。AIでも全く同じことがいえる。普通、最適なエポック数は学習データの量によって変わる。
### プロンプト
+ AIに質問するときに入力する文章のこと。厳密にいえば、AIに処理をさせる命令文。プロンプトの質が良いと、求めているデータや正確なデータを示してくれるが、質が悪いと、誤ったデータや意図にそぐわない返答が来ることもある。AIを使うのがうまい人とは、プロンプトの入力がうまい人。
